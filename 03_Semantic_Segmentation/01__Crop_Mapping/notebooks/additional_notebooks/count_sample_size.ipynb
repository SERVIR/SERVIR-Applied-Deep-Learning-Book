{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 NASA\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Rice mapping in Bhutan with U-Net using high resolution satellite imagery\n",
        "\n",
        "### This notebook shows an example of counting the sample size from the `tfrecords`\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/SERVIR/servir-aces/blob/main/notebooks/count_sample_size.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/SERVIR/servir-aces/blob/main/notebooks/count_sample_size.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "</table>\n",
        "</br>\n",
        "</br>\n",
        "</br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Zk3R20LkKet"
      },
      "source": [
        "This notebook is also available in this github repo: https://github.com/SERVIR/servir-aces. Navigate to the `notebooks` folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuQkhSxRmiIA"
      },
      "source": [
        "## Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuDztFucmhpB",
        "outputId": "427ef2d6-e718-4b10-f1d1-e19dfeaba07c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting servir-aces\n",
            "  Downloading servir_aces-0.0.14-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from servir-aces) (1.25.2)\n",
            "Requirement already satisfied: tensorflow>=2.9.3 in /usr/local/lib/python3.10/dist-packages (from servir-aces) (2.15.0)\n",
            "Requirement already satisfied: earthengine-api in /usr/local/lib/python3.10/dist-packages (from servir-aces) (0.1.399)\n",
            "Collecting python-dotenv>=1.0.0 (from servir-aces)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from servir-aces) (3.7.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (1.62.2)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.3->servir-aces) (2.15.0)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (from earthengine-api->servir-aces) (2.8.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.12.1 in /usr/local/lib/python3.10/dist-packages (from earthengine-api->servir-aces) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from earthengine-api->servir-aces) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from earthengine-api->servir-aces) (0.1.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from earthengine-api->servir-aces) (0.22.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from earthengine-api->servir-aces) (2.31.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->servir-aces) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->servir-aces) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->servir-aces) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->servir-aces) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->servir-aces) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->servir-aces) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->servir-aces) (2.8.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.9.3->servir-aces) (0.43.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.12.1->earthengine-api->servir-aces) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.12.1->earthengine-api->servir-aces) (4.1.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.4.1->earthengine-api->servir-aces) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.4.1->earthengine-api->servir-aces) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.4.1->earthengine-api->servir-aces) (4.9)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.3->servir-aces) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.3->servir-aces) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.3->servir-aces) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.3->servir-aces) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->earthengine-api->servir-aces) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->earthengine-api->servir-aces) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->earthengine-api->servir-aces) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->earthengine-api->servir-aces) (2024.2.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->earthengine-api->servir-aces) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->earthengine-api->servir-aces) (2.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api->servir-aces) (1.63.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.9.3->servir-aces) (1.3.1)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage->earthengine-api->servir-aces) (1.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->earthengine-api->servir-aces) (0.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.9.3->servir-aces) (2.1.5)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.9.3->servir-aces) (3.2.2)\n",
            "Installing collected packages: python-dotenv, servir-aces\n",
            "Successfully installed python-dotenv-1.0.1 servir-aces-0.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install servir-aces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PvoP9Sgqz4e",
        "outputId": "d45ebbf3-e7fa-4dcb-d3b0-a7b8455e61b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'servir-aces'...\n",
            "remote: Enumerating objects: 731, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 731 (delta 55), reused 40 (delta 40), pack-reused 641\u001b[K\n",
            "Receiving objects: 100% (731/731), 3.35 MiB | 4.84 MiB/s, done.\n",
            "Resolving deltas: 100% (478/478), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/SERVIR/servir-aces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RukLD6eeq7Fl"
      },
      "source": [
        "Now the repo is downloaded. We will create an environment file file to place point to our training data and customize parameters for the model. To do this, we make a copy of the `.env.example` file provided.\n",
        "\n",
        "Under the hood, all the configuration provided via the environment file are parsed as a config object and can be accessed programatically.\n",
        "\n",
        "Note current version does not expose all the model intracacies through the environment file but future version may include those depending on the need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jpnfjXRYsYMk"
      },
      "outputs": [],
      "source": [
        "!cp servir-aces/.env.example servir-aces/config.env"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOoH9ZJq0g80"
      },
      "source": [
        "## Setup config file variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooFqBUY3gS5e"
      },
      "source": [
        "Okay, now we have the `config.env` file, we will use this to provide our environments and parameters.\n",
        "\n",
        "Note there are several parameters that can be changed. Let's start by changing the BASEDIR as below.\n",
        "\n",
        "```\n",
        "BASEDIR = \"/content/\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oqyc1EHFhC9n"
      },
      "source": [
        "We will download data for this chapter. We will use `datasets` dir to download the data. Let's go ahead and create that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RnkHrSYThBZ1"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyyTqvnahc2h"
      },
      "source": [
        "Let's go ahead and download the datasets for which we need to calculate the number of samples. They can be found at the google cloud storage and we will use `gsutil` to get the dataset in our workspace. Each folder/ dataset has `training`, `testing`, and `validation` subdirectory. Let's start by downloading these datasets in our workspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ft4VMolhjgG",
        "outputId": "9de40f45-b2a1-4bb5-89fa-519652979b1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copying gs://dl-book/chapter-1/dnn_planet_wo_indices/training/training.tfrecord.gz...\n",
            "/ [0 files][    0.0 B/352.3 KiB]                                                \rCopying gs://dl-book/chapter-1/dnn_planet_wo_indices/testing/testing.tfrecord.gz...\n",
            "/ [0 files][    0.0 B/404.4 KiB]                                                \rCopying gs://dl-book/chapter-1/.DS_Store...\n",
            "/ [0 files][    0.0 B/410.4 KiB]                                                \rCopying gs://dl-book/chapter-1/dnn_planet_wo_indices/validation/validation.tfrecord.gz...\n",
            "/ [0 files][    0.0 B/512.0 KiB]                                                \rCopying gs://dl-book/chapter-1/images/image_202100001.tfrecord.gz...\n",
            "/ [0 files][    0.0 B/ 46.3 MiB]                                                \rCopying gs://dl-book/chapter-1/images/image_202100002.tfrecord.gz...\n",
            "/ [0 files][    0.0 B/ 93.3 MiB]                                                \rCopying gs://dl-book/chapter-1/images/image_202100003.tfrecord.gz...\n",
            "/ [0 files][    0.0 B/139.2 MiB]                                                \rCopying gs://dl-book/chapter-1/images/image_202100004.tfrecord.gz...\n",
            "/ [0 files][    0.0 B/181.7 MiB]                                                \rCopying gs://dl-book/chapter-1/images/image_202100000.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/images/image_202100005.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/images/image_2021mixer.json...\n",
            "Copying gs://dl-book/chapter-1/prediction/prediction_dnn_v1.TFRecord...\n",
            "==> NOTE: You are downloading one or more large file(s), which would\n",
            "run significantly faster if you enabled sliced object downloads. This\n",
            "feature is enabled by default but requires that compiled crcmod be\n",
            "installed (see \"gsutil help crcmod\").\n",
            "\n",
            "Copying gs://dl-book/chapter-1/prediction/prediction_unet_v1.TFRecord...\n",
            "Copying gs://dl-book/chapter-1/training_data/testing_10/testing__256x256-00000-of-00008.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/training_data/testing_10/testing__256x256-00001-of-00008.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/training_data/testing_10/testing__256x256-00002-of-00008.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/training_data/testing_10/testing__256x256-00003-of-00008.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/training_data/testing_10/testing__256x256-00004-of-00008.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/training_data/testing_10/testing__256x256-00005-of-00008.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/training_data/testing_10/testing__256x256-00006-of-00008.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/training_data/testing_10/testing__256x256-00007-of-00008.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00000-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00001-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00002-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00003-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00004-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00005-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00006-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00007-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00008-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00009-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00010-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00011-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00012-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00013-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00014-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00015-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00016-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00017-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00018-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00019-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00020-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00021-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00022-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00023-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00024-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00025-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00026-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00027-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00028-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00029-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00030-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00031-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00032-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00033-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00035-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00034-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00036-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/testing/testing-00037-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00000-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00001-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00002-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00003-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00004-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00005-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00006-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00007-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00008-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00009-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00010-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00011-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00012-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00013-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00014-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00015-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00016-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00017-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00018-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00019-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00020-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00021-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00022-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00023-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00024-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00025-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00026-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00027-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00028-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00029-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00030-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00031-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00032-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00033-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00034-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00035-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00036-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/training/training-00037-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00000-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00001-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00002-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00003-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00004-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00005-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00006-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00007-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00008-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00009-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00010-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00011-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00012-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00013-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00014-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00015-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00016-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00017-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00018-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00019-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00020-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00021-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00022-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00023-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00024-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00025-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00026-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00027-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00028-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00029-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00030-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00031-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00032-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00033-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00034-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00035-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00036-of-00038.tfrecord.gz...\n",
            "Copying gs://dl-book/chapter-1/unet_256x256_planet_wo_indices/validation/validation-00037-of-00038.tfrecord.gz...\n"
          ]
        }
      ],
      "source": [
        "!gsutil -m cp -r gs://dl-book/chapter-1/* /content/datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Orc9Qcb3shcu"
      },
      "source": [
        "We will use the `unet_256x256_planet_wo_indices` dataset inside the `dataset` folder for this exercise. Let's go ahead and change our DATADIR in the `config.env` file as below.\n",
        "\n",
        "```\n",
        "DATADIR = \"datasets/unet_256x256_planet_wo_indices\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEDUshfUi1OY"
      },
      "source": [
        "These datasets have RGBN from Planetscope mosiac. Since we are trying to map the rice fields, we use growing season and pre-growing season information. Thus, we have 8 optical bands, namely `red_before`, `green_before`, `blue_before`, `nir_before`, `red_during`, `green_during`, `blue_during`, and  `nir_during`. In adidition, you can use `USE_ELEVATION` and `USE_S1` config to include the topographic and radar information. Since currently we are not including these, so we won't be settting these config values. Similarly, these datasets are tiled to 256x256 pixels, so let's also change that.\n",
        "\n",
        "```\n",
        "# For model training, USE_ELEVATION extends FEATURES with \"elevation\" & \"slope\"\n",
        "# USE_S1 extends FEATURES with \"vv_asc_before\", \"vh_asc_before\", \"vv_asc_during\", \"vh_asc_during\",\n",
        "# \"vv_desc_before\", \"vh_desc_before\", \"vv_desc_during\", \"vh_desc_during\"\n",
        "# In case these are not useful and you have other bands in your training data, you can do set\n",
        "# USE_ELEVATION and USE_S1 to False and update FEATURES to include needed bands\n",
        "USE_ELEVATION = False\n",
        "USE_S1 = False\n",
        "\n",
        "PATCH_SHAPE = (256, 256)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6NF86anh-pS"
      },
      "source": [
        "Next, we need to calculate the size of the traiing, testing and validation dataset. For this, we know our size before hand. But let's use `aces` useful functionality to calculate this.\n",
        "\n",
        "```\n",
        "# Sizes of the training and evaluation datasets.\n",
        "TRAIN_SIZE = 8531\n",
        "TEST_SIZE = 1222\n",
        "VAL_SIZE = 2404\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfPDbBLV0lsL"
      },
      "source": [
        "## Update the config file programtically"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNPTVh3b0ni-"
      },
      "source": [
        "Let's make a dictionary so we can change these config settings programatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_siYzZ0c0ptu"
      },
      "outputs": [],
      "source": [
        "BASEDIR = \"/content/\" # @param {type:\"string\"}\n",
        "DATADIR = \"datasets/unet_256x256_planet_wo_indices\" # @param {type:\"string\"}\n",
        "\n",
        "USE_ELEVATION = \"False\" # @param {type:\"string\"}\n",
        "USE_S1 = \"False\" # @param {type:\"string\"}\n",
        "PATCH_SHAPE = \"(256, 256)\" # @param {type:\"string\"}\n",
        "\n",
        "BATCH_SIZE = \"32\" # @param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qQrcO_Jr2qxq"
      },
      "outputs": [],
      "source": [
        "config_settings = {\n",
        "    \"BASEDIR\" : BASEDIR,\n",
        "    \"DATADIR\": DATADIR,\n",
        "    \"USE_ELEVATION\": USE_ELEVATION,\n",
        "    \"USE_S1\": USE_S1,\n",
        "    \"PATCH_SHAPE\": PATCH_SHAPE,\n",
        "    \"BATCH_SIZE\": BATCH_SIZE,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6HD5aB2D2wfy"
      },
      "outputs": [],
      "source": [
        "import dotenv\n",
        "\n",
        "config_file = \"servir-aces/config.env\"\n",
        "\n",
        "for config_key in config_settings:\n",
        "    dotenv.set_key(dotenv_path=config_file,\n",
        "                   key_to_set=config_key,\n",
        "                   value_to_set=config_settings[config_key]\n",
        "                   )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRMRDBh82ziD"
      },
      "source": [
        "## Load config file variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AWToBRVmqkok"
      },
      "outputs": [],
      "source": [
        "from aces import Config, DataProcessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0zB2echioW0",
        "outputId": "d656766c-0b2c-4b1c-9f0c-2c5223295309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BASEDIR: /content\n",
            "DATADIR: /content/datasets/unet_256x256_planet_wo_indices\n",
            "using features: ['red_before', 'green_before', 'blue_before', 'nir_before', 'red_during', 'green_during', 'blue_during', 'nir_during']\n",
            "using labels: ['class']\n"
          ]
        }
      ],
      "source": [
        "config_file = \"/content/servir-aces/config.env\"\n",
        "config = Config(config_file, override=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPKv3W5crsf1"
      },
      "source": [
        "Most of the config in the `config.env` is now available via the config instance. Let's check few of them here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dgS1btomEqO",
        "outputId": "150fc46f-b902-4ba0-cc6d-7dfb2c535b41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(PosixPath('/content/datasets/unet_256x256_planet_wo_indices/training'),\n",
              " 32,\n",
              " ['red_before',\n",
              "  'green_before',\n",
              "  'blue_before',\n",
              "  'nir_before',\n",
              "  'red_during',\n",
              "  'green_during',\n",
              "  'blue_during',\n",
              "  'nir_during'])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config.TRAINING_DIR, config.BATCH_SIZE, config.FEATURES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGbpDtPlf9_O"
      },
      "source": [
        "## Calculate the number of records"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYvPo_P5gB1n"
      },
      "source": [
        "Use the `calculate_n_samples` static function of the `DataProcessor` class to get the number of records for each split. You can provide additional parameters (`PRINT_DATASET`) as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b9Gm_VSixBz",
        "outputId": "9518129d-a15f-475e-b13c-b7b5be2a62b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training\n",
            "inputs: float32 (256, 256, 8)\n",
            "tf.Tensor(\n",
            "[[[0.04035  0.0461   0.0259   ... 0.03885  0.0167   0.167425]\n",
            "  [0.03675  0.044525 0.02385  ... 0.0367   0.015075 0.15035 ]\n",
            "  [0.0288   0.039725 0.022375 ... 0.03295  0.01355  0.144725]\n",
            "  ...\n",
            "  [0.029625 0.044825 0.02755  ... 0.0371   0.017125 0.172825]\n",
            "  [0.027825 0.0424   0.0271   ... 0.036675 0.016825 0.169375]\n",
            "  [0.029975 0.046125 0.0272   ... 0.037925 0.01715  0.174475]]\n",
            "\n",
            " [[0.0328   0.0432   0.0236   ... 0.03615  0.014875 0.159375]\n",
            "  [0.0273   0.039525 0.0219   ... 0.031475 0.013425 0.139925]\n",
            "  [0.0321   0.04045  0.02235  ... 0.0346   0.014325 0.152   ]\n",
            "  ...\n",
            "  [0.029825 0.0453   0.02725  ... 0.03725  0.01675  0.1777  ]\n",
            "  [0.0305   0.04465  0.0276   ... 0.03825  0.017225 0.17445 ]\n",
            "  [0.03075  0.047175 0.027475 ... 0.039175 0.017775 0.17845 ]]\n",
            "\n",
            " [[0.029575 0.04125  0.02265  ... 0.03425  0.014675 0.1507  ]\n",
            "  [0.024    0.038475 0.02175  ... 0.029925 0.012125 0.1312  ]\n",
            "  [0.031825 0.0415   0.0228   ... 0.03515  0.01495  0.1445  ]\n",
            "  ...\n",
            "  [0.030975 0.04515  0.027625 ... 0.038175 0.0172   0.17785 ]\n",
            "  [0.03175  0.046125 0.0285   ... 0.04035  0.017775 0.18125 ]\n",
            "  [0.0317   0.048    0.0282   ... 0.0398   0.0171   0.1855  ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.09805  0.09635  0.074375 ... 0.055425 0.02635  0.23565 ]\n",
            "  [0.0949   0.088425 0.072575 ... 0.05455  0.02595  0.250725]\n",
            "  [0.0947   0.091025 0.071425 ... 0.05145  0.024825 0.2485  ]\n",
            "  ...\n",
            "  [0.07875  0.069325 0.04305  ... 0.071225 0.045425 0.302775]\n",
            "  [0.072325 0.068075 0.043    ... 0.065475 0.042125 0.30345 ]\n",
            "  [0.06735  0.062125 0.03735  ... 0.06095  0.03875  0.309275]]\n",
            "\n",
            " [[0.092375 0.093225 0.0726   ... 0.05565  0.0267   0.240025]\n",
            "  [0.094625 0.089775 0.0718   ... 0.054675 0.025675 0.251225]\n",
            "  [0.094325 0.0928   0.07335  ... 0.05325  0.0247   0.27065 ]\n",
            "  ...\n",
            "  [0.111025 0.088825 0.062725 ... 0.09535  0.064175 0.29085 ]\n",
            "  [0.099925 0.0841   0.05815  ... 0.09325  0.06745  0.286575]\n",
            "  [0.091975 0.08135  0.056225 ... 0.089575 0.06185  0.28065 ]]\n",
            "\n",
            " [[0.092575 0.090825 0.069    ... 0.055525 0.02595  0.245075]\n",
            "  [0.092725 0.090775 0.067725 ... 0.053675 0.025225 0.2487  ]\n",
            "  [0.095    0.094375 0.07145  ... 0.0536   0.024225 0.2796  ]\n",
            "  ...\n",
            "  [0.117025 0.09645  0.0705   ... 0.118475 0.08195  0.272875]\n",
            "  [0.10465  0.08295  0.060175 ... 0.0951   0.07255  0.2546  ]\n",
            "  [0.097475 0.0948   0.0681   ... 0.105525 0.082425 0.247325]]], shape=(256, 256, 8), dtype=float32)\n",
            "outputs: float32 (256, 256, 5)\n",
            "tf.Tensor(\n",
            "[[[1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 1. 0. 0.]\n",
            "  [0. 0. 1. 0. 0.]\n",
            "  [0. 0. 1. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 1. 0. 0.]\n",
            "  [0. 0. 1. 0. 0.]\n",
            "  [0. 0. 1. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 1. 0. 0.]\n",
            "  [0. 0. 1. 0. 0.]\n",
            "  [0. 0. 1. 0. 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0. 1. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0.]\n",
            "  ...\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. 1. 0.]\n",
            "  [0. 0. 0. 1. 0.]\n",
            "  [0. 0. 1. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. 1. 0.]\n",
            "  [0. 0. 0. 1. 0.]\n",
            "  [0. 0. 0. 1. 0.]]], shape=(256, 256, 5), dtype=float32)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/aces/data_processor.py:55: ignore_errors (from tensorflow.python.data.experimental.ops.error_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.ignore_errors` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 47s, sys: 11.2 s, total: 3min 58s\n",
            "Wall time: 3min 45s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "additional_config = {\n",
        "    \"PRINT_DATASET\": True\n",
        "}\n",
        "n_training_records, n_testing_records, n_validation_records = DataProcessor.calculate_n_samples(**{**config.__dict__, **additional_config})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1v6DU2umAzp",
        "outputId": "6b58c435-b312-4b02-e2b8-79695957b4a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "no of training records: 8531\n",
            "no of testing records: 1222\n",
            "no of validation records: 2404\n"
          ]
        }
      ],
      "source": [
        "print(f\"no of training records: {n_training_records}\")\n",
        "print(f\"no of testing records: {n_testing_records}\")\n",
        "print(f\"no of validation records: {n_validation_records}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NI3DZXi8Po4j"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
